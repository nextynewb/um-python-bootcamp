{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Name': ['Ahmad', 'Siti', 'Aniq', 'Sarah', 'Malik', 'John', 'Mary', 'Ali', 'Lisa', 'David', 'Emma', 'Hassan', 'Fatima', 'James', 'Anna', 'Ahmad'],\n",
    "    'Register_Date': ['15/01/2023', '01/02/2023', '20/01/2023', '10/03/2023', '15/02/2023', '05/01/2023', '28/02/2023', '15/03/2023', '30/01/2023', '10/02/2023', '01/03/2023', '25/01/2023', '20/02/2023', '05/03/2023', '10/01/2023', '15/01/2023'],\n",
    "    'ID': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1001],\n",
    "    'Age': ['28', None, '32', '27', '30', '35', '29', None, '31', '33', '26', None, '34', '28', '32', '28'],\n",
    "    'Salary': [50000, 45000, None, 55000, 60000, 65000, 48000, 52000, None, 70000, 51000, 53000, None, 57000, 62000, 50000],\n",
    "    'Experience': [3, 2, 6, None, 5, 8, 4, 3, 5, None, 2, 7, 6, None, 4, 3],\n",
    "    'Performance_Score': [8.5, 7.9, 9.2, 8.7, None, 8.9, None, 8.2, 9.0, 8.8, 7.8, 9.1, 8.4, 8.6, None, 8.5],\n",
    "    'Department': ['Sales', 'IT', None, 'HR', 'Marketing', 'Sales', 'IT', 'Marketing', None, 'HR', 'Sales', None, 'IT', 'Marketing', 'HR', 'Sales'],\n",
    "    'Projects_Completed': [12, 8, 15, None, 10, 14, 9, None, 11, 13, None, 16, 7, 12, 9, 12],\n",
    "    'Training_Hours': [40, None, 60, 35, 45, None, 50, 40, 55, 30, 45, None, 50, 35, 40, 40],\n",
    "    'Leave_Days': [10, 12, None, 8, 15, 7, None, 11, 9, 14, 8, 13, None, 10, 12, 10],\n",
    "    'Bonus': [2000, None, 3500, 2500, 4000, 3000, 2200, None, 2800, 4500, 2100, 3200, None, 2700, 3800, 2000]\n",
    "}\n",
    "\n",
    "# Initialize DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the index\n",
    "\n",
    "df.set_index('ID', inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing the data using .loc[index]\n",
    "\n",
    "df.loc[1002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new data using loc[index]\n",
    "\n",
    "new_data = {\n",
    "    'Name': 'Raj',\n",
    "    'Age': 25,\n",
    "    'Salary': 50000,\n",
    "    'Experience': 3,\n",
    "    'Performance_Score': 8.5,\n",
    "    'Department': 'IT',\n",
    "    'Projects_Completed': 12,\n",
    "    'Training_Hours': 40,\n",
    "    'Leave_Days': 10,\n",
    "    'Bonus': 2000\n",
    "}\n",
    "\n",
    "df.loc[1016] = new_data\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Read CSV file\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "Read Excel file\n",
    "df = pd.read_excel('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.xlsx')\n",
    "\n",
    "Read JSON file\n",
    "df = pd.read_json('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.json')\n",
    "\n",
    "Read Parquet file\n",
    "df = pd.read_parquet('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.parquet')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"The shape of the dataframe is {df.shape}\")\n",
    "print('-------')\n",
    "\n",
    "print(f\"The columns of the dataframe are {df.columns}\")\n",
    "print('-------')\n",
    "\n",
    "\n",
    "print(f\"The head of the dataframe is {df.head()}\")\n",
    "print('-------')\n",
    "\n",
    "\n",
    "print(f\"The tail of the dataframe is {df.tail()}\")\n",
    "print('-------')\n",
    "\n",
    "\n",
    "print(f\"The null values of the dataframe are {df.isnull().sum()}\")\n",
    "print('-------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df = df.drop(columns=['Performance_Score'])\n",
    "\n",
    "filter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_duplicate_df = df.drop_duplicates()\n",
    "\n",
    "drop_duplicate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Handling Null Values\n",
    "\n",
    "1. Impute the null values with the mean, median, mode\n",
    "2. Fill in with any value\n",
    "3. Drop the rows with null values\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# (1): Impute the null values with the mean, median, mode\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "\n",
    "print(f\"The mean of the Salary column is {df['Salary'].median()}\")\n",
    "\n",
    "df['Salary'].fillna(df['Salary'].median(), inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (2): Filling null values with any value\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df['Salary'].fillna(1000, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (3): Dropping the rows with null values\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Changing the Data Types\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'Name': ['Ahmad', 'Siti', 'Aniq', 'Sarah', 'Malik', 'John', 'Mary', 'Ali', 'Lisa', 'David', 'Emma', 'Hassan', 'Fatima', 'James', 'Anna', 'Ahmad'],\n",
    "    'Register_Date': ['15/01/2023', '01/02/2023', '20/01/2023', '10/03/2023', '15/02/2023', '05/01/2023', '28/02/2023', '15/03/2023', '30/01/2023', '10/02/2023', '01/03/2023', '25/01/2023', '20/02/2023', '05/03/2023', '10/01/2023', '15/01/2023'],\n",
    "    'ID': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1001],\n",
    "    'Age': ['28', None, '32', '27', '30', '35', '29', None, '31', '33', '26', None, '34', '28', '32', '28'],\n",
    "    'Salary': [50000, 45000, None, 55000, 60000, 65000, 48000, 52000, None, 70000, 51000, 53000, None, 57000, 62000, 50000],\n",
    "    'Experience': [3, 2, 6, None, 5, 8, 4, 3, 5, None, 2, 7, 6, None, 4, 3],\n",
    "    'Performance_Score': [8.5, 7.9, 9.2, 8.7, None, 8.9, None, 8.2, 9.0, 8.8, 7.8, 9.1, 8.4, 8.6, None, 8.5],\n",
    "    'Department': ['Sales', 'IT', None, 'HR', 'Marketing', 'Sales', 'IT', 'Marketing', None, 'HR', 'Sales', None, 'IT', 'Marketing', 'HR', 'Sales'],\n",
    "    'Projects_Completed': [12, 8, 15, None, 10, 14, 9, None, 11, 13, None, 16, 7, 12, 9, 12],\n",
    "    'Training_Hours': [40, None, 60, 35, 45, None, 50, 40, 55, 30, 45, None, 50, 35, 40, 40],\n",
    "    'Leave_Days': [10, 12, None, 8, 15, 7, None, 11, 9, 14, 8, 13, None, 10, 12, 10],\n",
    "    'Bonus': [2000, None, 3500, 2500, 4000, 3000, 2200, None, 2800, 4500, 2100, 3200, None, 2700, 3800, 2000]\n",
    "}\n",
    "\n",
    "# Initialize DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df.dtypes)\n",
    "print('-------')\n",
    "\n",
    "\"\"\"\n",
    "Based on observation, we can see that the Age column is a string (Object).\n",
    "\n",
    "Remarks: You can't convert the Age column to integer because it contains null values.\n",
    "So, we need to drop the rows with null values in the 'Age' column only then we can convert the Age column to integer.\n",
    "\n",
    "# Convert the Age column to integer\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "\n",
    "print(df.dtypes)\n",
    "\"\"\"\n",
    "\n",
    "# Drop rows with null values in the 'Age' column only\n",
    "df = df.dropna(subset=['Age'])\n",
    "\n",
    "# Now we can safely convert Age to integer\n",
    "df['Age'] = df['Age'].astype(int)\n",
    "\n",
    "print(f\"After the change, the data types of the columns are:\")\n",
    "print(df.dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's say for whatever reason, you need to change the 'Age' to String\n",
    "\"\"\"\n",
    "\n",
    "df['Age'] = df['Age'].astype(str)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Changing Str to Datetime\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'Name': ['Ahmad', 'Siti', 'Aniq', 'Sarah', 'Malik', 'John', 'Mary', 'Ali', 'Lisa', 'David', 'Emma', 'Hassan', 'Fatima', 'James', 'Anna', 'Ahmad'],\n",
    "    'Register_Date': ['15/01/2023', '01/02/2023', '20/01/2023', '10/03/2023', '15/02/2023', '05/01/2023', '28/02/2023', '15/03/2023', '30/01/2023', '10/02/2023', '01/03/2023', '25/01/2023', '20/02/2023', '05/03/2023', '10/01/2023', '15/01/2023'],\n",
    "    'Quitting_Date': ['15-12-2023', '20-11-2023', '05-10-2023', '30-09-2023', '15-08-2023', '01-07-2023', '10-06-2023', '25-05-2023', '12-04-2023', '28-03-2023', '17-04-2023', '22-01-2024', '08-03-2024', '19-04-2024', '30-05-2024', '14-06-2024'],\n",
    "    'ID': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1001],\n",
    "    'Age': ['28', None, '32', '27', '30', '35', '29', None, '31', '33', '26', None, '34', '28', '32', '28'],\n",
    "    'Salary': [50000, 45000, None, 55000, 60000, 65000, 48000, 52000, None, 70000, 51000, 53000, None, 57000, 62000, 50000],\n",
    "    'Experience': [3, 2, 6, None, 5, 8, 4, 3, 5, None, 2, 7, 6, None, 4, 3],\n",
    "    'Performance_Score': [8.5, 7.9, 9.2, 8.7, None, 8.9, None, 8.2, 9.0, 8.8, 7.8, 9.1, 8.4, 8.6, None, 8.5],\n",
    "    'Department': ['Sales', 'IT', None, 'HR', 'Marketing', 'Sales', 'IT', 'Marketing', None, 'HR', 'Sales', None, 'IT', 'Marketing', 'HR', 'Sales'],\n",
    "    'Projects_Completed': [12, 8, 15, None, 10, 14, 9, None, 11, 13, None, 16, 7, 12, 9, 12],\n",
    "    'Training_Hours': [40, None, 60, 35, 45, None, 50, 40, 55, 30, 45, None, 50, 35, 40, 40],\n",
    "    'Leave_Days': [10, 12, None, 8, 15, 7, None, 11, 9, 14, 8, 13, None, 10, 12, 10],\n",
    "    'Bonus': [2000, None, 3500, 2500, 4000, 3000, 2200, None, 2800, 4500, 2100, 3200, None, 2700, 3800, 2000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.dtypes\n",
    "\n",
    "df['Register_Date'] = pd.to_datetime(df['Register_Date'], format='%d/%m/%Y')\n",
    "df['Quitting_Date'] = pd.to_datetime(df['Quitting_Date'], format='%d-%m-%Y')\n",
    "df.dtypes\n",
    "\n",
    "df['Work Period'] = df['Quitting_Date'] - df['Register_Date']\n",
    "\n",
    "df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Column Selection\n",
    "\"\"\"\n",
    "\n",
    "data = {\n",
    "    'Name': ['Ahmad', 'Siti', 'Aniq', 'Sarah', 'Malik', 'John', 'Mary', 'Ali', 'Lisa', 'David', 'Emma', 'Hassan', 'Fatima', 'James', 'Anna', 'Ahmad'],\n",
    "    'Register_Date': ['15/01/2023', '01/02/2023', '20/01/2023', '10/03/2023', '15/02/2023', '05/01/2023', '28/02/2023', '15/03/2023', '30/01/2023', '10/02/2023', '01/03/2023', '25/01/2023', '20/02/2023', '05/03/2023', '10/01/2023', '15/01/2023'],\n",
    "    'Quitting_Date': ['15-12-2023', '20-11-2023', '05-10-2023', '30-09-2023', '15-08-2023', '01-07-2023', '10-06-2023', '25-05-2023', '12-04-2023', '28-03-2023', '17-04-2023', '22-01-2024', '08-03-2024', '19-04-2024', '30-05-2024', '14-06-2024'],\n",
    "    'ID': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1001],\n",
    "    'Age': ['28', None, '32', '27', '30', '35', '29', None, '31', '33', '26', None, '34', '28', '32', '28'],\n",
    "    'Salary': [50000, 45000, None, 55000, 60000, 65000, 48000, 52000, None, 70000, 51000, 53000, None, 57000, 62000, 50000],\n",
    "    'Experience': [3, 2, 6, None, 5, 8, 4, 3, 5, None, 2, 7, 6, None, 4, 3],\n",
    "    'Performance_Score': [8.5, 7.9, 9.2, 8.7, None, 8.9, None, 8.2, 9.0, 8.8, 7.8, 9.1, 8.4, 8.6, None, 8.5],\n",
    "    'Department': ['Sales', 'IT', None, 'HR', 'Marketing', 'Sales', 'IT', 'Marketing', None, 'HR', 'Sales', None, 'IT', 'Marketing', 'HR', 'Sales'],\n",
    "    'Projects_Completed': [12, 8, 15, None, 10, 14, 9, None, 11, 13, None, 16, 7, 12, 9, 12],\n",
    "    'Training_Hours': [40, None, 60, 35, 45, None, 50, 40, 55, 30, 45, None, 50, 35, 40, 40],\n",
    "    'Leave_Days': [10, 12, None, 8, 15, 7, None, 11, 9, 14, 8, 13, None, 10, 12, 10],\n",
    "    'Bonus': [2000, None, 3500, 2500, 4000, 3000, 2200, None, 2800, 4500, 2100, 3200, None, 2700, 3800, 2000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df = df.get(['Name']) # or df[['Name']]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Row Filtering\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df = df[df['Salary'] > 50000]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Multi-row Filtering\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df = df[(df['Salary'] > 50000) & (df['Performance_Score'] < 8)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Row Filtering for Date\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df['Register_Date'] = pd.to_datetime(df['Register_Date'], format='%d/%m/%Y')\n",
    "\n",
    "df = df[df['Register_Date'] > '2023-01-20']\n",
    "\n",
    "# or you can use the following code\n",
    "# df = df[df['Register_Date'].dt.month == 1]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Row Filtering + Column Selection\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df = df[(df['Salary'] > 50000)].get(['Name', 'Salary'])\n",
    "\n",
    "# or you can inversely select the rows first then select the columns\n",
    "\n",
    "df = df.get(['Name', 'Salary'])[(df['Salary'] > 50000)]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Row Slicing\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df = df.iloc[0:10]\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add Column with Constant Value\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df['Department'] = 'IT'\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add Column with Existing Column\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df['Increment_Salary'] = df['Salary'] * 0.1\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add column with hardcoded value\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df['Number_of_Projects'] = [10, 12, 15, 10, 14, 16, 9, 11, 13, 16, 7, 12, 9, 12, 20, 20]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add Column with String Manipulation\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df['Name'] = df['Name'].str.lower()\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add column with date manipulation\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df['Register_Date'] = pd.to_datetime(df['Register_Date'], format='%d/%m/%Y')\n",
    "\n",
    "df['Register_Month'] = df['Register_Date'].dt.month\n",
    "\n",
    "df['Register_Year'] = df['Register_Date'].dt.year\n",
    "\n",
    "df['Register_Day'] = df['Register_Date'].dt.day\n",
    "\n",
    "df.get(['Register_Date', 'Register_Month', 'Register_Year', 'Register_Day'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add Column data with Function\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "\n",
    "def salary_level(salary):\n",
    "    if salary < 50000:\n",
    "        return 'High'\n",
    "    elif salary >= 50000 and salary < 100000:\n",
    "        return 'Middle'\n",
    "    else:\n",
    "        return 'Low'\n",
    "    \n",
    "\n",
    "df['Salary_Level'] = df['Salary'].apply(salary_level)\n",
    "\n",
    "df.get(['Name', 'Salary', 'Salary_Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Add Column data with Function\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "\n",
    "def salary_level(row):\n",
    "    if row['Salary'] < 50000:\n",
    "        return 'High'\n",
    "    elif row['Salary'] >= 50000 and row['Salary'] < 100000:\n",
    "        return 'Middle'\n",
    "    else:\n",
    "        return 'Low'\n",
    "    \n",
    "df['Salary_Level'] = df.apply(salary_level, axis=1)\n",
    "\n",
    "df.get(['Name', 'Salary', 'Salary_Level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Exercise\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Creating a dictionary with country data\n",
    "countries_data = {\n",
    "    'Country': [\n",
    "        'United States', 'China', 'Japan', 'Germany', 'India', \n",
    "        'United Kingdom', 'France', 'Brazil', 'Italy', 'Canada',\n",
    "        'South Korea', 'Australia', 'Spain', 'Mexico', 'Indonesia',\n",
    "        'Netherlands', 'Saudi Arabia', 'Turkey', 'Switzerland', 'Poland',\n",
    "        'Sweden', 'Belgium', 'Nigeria', 'Argentina', 'Norway',\n",
    "        'Austria', 'Thailand', 'United Arab Emirates', 'Egypt', 'Ireland',\n",
    "        'Singapore', 'Malaysia', 'South Africa', 'Philippines', 'Colombia',\n",
    "        'Pakistan', 'Chile', 'Vietnam', 'Bangladesh', 'New Zealand'\n",
    "    ],\n",
    "    'Continent': [\n",
    "        'North America', 'Asia', 'Asia', 'Europe', 'Asia',\n",
    "        'Europe', 'Europe', 'South America', 'Europe', 'North America',\n",
    "        'Asia', 'Oceania', 'Europe', 'North America', 'Asia',\n",
    "        'Europe', 'Asia', 'Asia', 'Europe', 'Europe',\n",
    "        'Europe', 'Europe', 'Africa', 'South America', 'Europe',\n",
    "        'Europe', 'Asia', 'Asia', 'Africa', 'Europe',\n",
    "        'Asia', 'Asia', 'Africa', 'Asia', 'South America',\n",
    "        'Asia', 'South America', 'Asia', 'Asia', 'Oceania'\n",
    "    ],\n",
    "    'Date_Joined_UN': [\n",
    "        '1945-10-24', '1945-10-24', '1956-12-18', '1973-09-18', '1945-10-30',\n",
    "        '1945-10-24', '1945-10-24', '1945-10-24', '1955-12-14', '1945-11-09',\n",
    "        '1991-09-17', '1945-11-01', '1955-12-14', '1945-11-07', '1950-09-28',\n",
    "        '1945-12-10', '1945-10-24', '1945-10-24', '2002-09-10', '1945-10-24',\n",
    "        '1946-11-19', '1945-12-27', '1960-10-07', '1945-10-24', '1945-11-27',\n",
    "        '1955-12-14', '1946-12-16', '1971-12-09', '1945-10-24', '1955-12-14',\n",
    "        '1965-09-21', '1957-09-17', '1945-11-07', '1945-10-24', '1945-11-05',\n",
    "        '1947-09-30', '1945-10-24', '1977-09-20', '1974-09-17', '1945-10-24'\n",
    "    ],\n",
    "    'GDP_Growth_Rate': [\n",
    "        2.3, 6.1, 0.7, 1.5, 4.2,\n",
    "        1.4, 1.5, 1.1, 0.3, 1.6,\n",
    "        2.0, 2.2, 2.0, 2.0, 5.0,\n",
    "        1.7, None, 0.9, 1.1, 4.1,\n",
    "        1.2, 1.4, 2.2, -2.2, 1.2,\n",
    "        1.6, 2.4, 1.7, 5.6, 5.5,\n",
    "        0.7, 4.3, 0.2, 5.9, 3.3,\n",
    "        1.0, 1.1, 7.0, 8.2, 2.2\n",
    "    ],\n",
    "    'Population_Millions': [\n",
    "        331.0, 1412.0, 125.7, 83.2, 1380.0,\n",
    "        67.9, 65.3, 212.6, 60.5, 38.0,\n",
    "        51.7, 25.7, 47.4, 128.9, 273.5,\n",
    "        17.1, 34.8, 84.3, 8.6, 37.8,\n",
    "        10.4, 11.6, 206.1, 45.2, 5.4,\n",
    "        9.0, 69.8, 9.9, 102.3, 4.9,\n",
    "        5.7, 32.4, 59.3, 109.6, 50.9,\n",
    "        220.9, 19.1, 97.3, 164.7, 5.1\n",
    "    ],\n",
    "    'GDP_Billions': [\n",
    "        21433, 14343, 5082, 3846, None,\n",
    "        2829, 2716, 1830, 1886, 1643,\n",
    "        1630, 1323, 1281, 1076, 1058,\n",
    "        907, 793, 760, 703, 594,\n",
    "        541, 515, None, 445, 403,\n",
    "        417, 505, 421, 303, 388,\n",
    "        340, 336, 329, 331, 314,\n",
    "        282, 282, 261, 249, 206\n",
    "    ],\n",
    "    'Birth_Rate': [\n",
    "        11.6, 11.3, 7.3, 9.5, 17.5,\n",
    "        10.7, 11.2, 13.9, 7.0, 10.1,\n",
    "        6.4, 12.1, 7.4, 17.6, None,\n",
    "        9.8, 14.7, 15.3, 10.5, 9.1,\n",
    "        11.3, 9.9, 35.2, 16.5, 9.9,\n",
    "        9.8, None, 9.8, 27.2, 11.2,\n",
    "        8.9, 16.4, 19.2, 22.1, 14.8,\n",
    "        27.4, 12.4, None, 18.1, 12.8\n",
    "    ],\n",
    "    'Internet_Users_Percent': [\n",
    "        '89.4', '64.5', '93.7', '89.7', '50.0',\n",
    "        '94.9', '85.6', '74.0', '74.4', '91.6',\n",
    "        '96.2', '86.5', '93.2', '70.1', '53.7',\n",
    "        '93.2', '95.7', '77.7', '93.1', '78.3',\n",
    "        '94.5', '90.7', '42.0', '74.3', '96.5',\n",
    "        '87.9', '77.8', '99.1', '57.3', '84.5',\n",
    "        '88.4', '84.2', '56.2', '72.0', '65.0',\n",
    "        '17.1', '82.3', '70.3', '22.0', '90.8'\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Exercise\n",
    "\n",
    "1. Handle null values with imputing with mean.\n",
    "2. Change Datatype of Internet_Users_Percent to float.\n",
    "3. Change datatype of Date_Joined_UN to datetime.\n",
    "4. Get Actual number of Internet Users in Millions from the Internet_Users_Percent * Population_Millions.\n",
    "5. Label Internet Users based on the following criteria and add to a new column called \"Internet_Users_Label\":\n",
    "    - High: 30 million or more\n",
    "    - Medium: 10 million to 30 million\n",
    "    - Low: Less than 10 million\n",
    "\n",
    "\"\"\"\n",
    "df = pd.DataFrame(countries_data)\n",
    "df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregation Data\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df\n",
    "df['Experience'] = df['Experience'].fillna(df['Experience'].mean())\n",
    "df['Performance_Score'] = df['Performance_Score'].fillna(df['Performance_Score'].mean())\n",
    "df['Projects_Completed'] = df['Projects_Completed'].fillna(df['Projects_Completed'].mean())\n",
    "df['Training_Hours'] = df['Training_Hours'].fillna(df['Training_Hours'].mean())\n",
    "df['Leave_Days'] = df['Leave_Days'].fillna(df['Leave_Days'].mean())\n",
    "df['Bonus'] = df['Bonus'].fillna(df['Bonus'].mean())\n",
    "\n",
    "df_agg = df.agg({\n",
    "    'Salary': ['mean', 'median', 'max'],\n",
    "    'Experience': ['mean', 'median', 'min', 'max'],\n",
    "})\n",
    "\n",
    "df_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aggregation Data with Group By\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df\n",
    "df['Experience'] = df['Experience'].fillna(df['Experience'].mean())\n",
    "df['Performance_Score'] = df['Performance_Score'].fillna(df['Performance_Score'].mean())\n",
    "df['Projects_Completed'] = df['Projects_Completed'].fillna(df['Projects_Completed'].mean())\n",
    "df['Training_Hours'] = df['Training_Hours'].fillna(df['Training_Hours'].mean())\n",
    "df['Leave_Days'] = df['Leave_Days'].fillna(df['Leave_Days'].mean())\n",
    "df['Bonus'] = df['Bonus'].fillna(df['Bonus'].mean())\n",
    "\n",
    "df_agg = df.groupby('Department').agg({\n",
    "    'Salary': ['mean', 'median', 'max'],\n",
    "    'Experience': ['mean', 'median', 'min', 'max'],\n",
    "})\n",
    "\n",
    "df_agg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Correlation Data\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/employee_data.csv')\n",
    "\n",
    "df\n",
    "df['Experience'] = df['Experience'].fillna(df['Experience'].mean())\n",
    "df['Performance_Score'] = df['Performance_Score'].fillna(df['Performance_Score'].mean())\n",
    "df['Projects_Completed'] = df['Projects_Completed'].fillna(df['Projects_Completed'].mean())\n",
    "df['Training_Hours'] = df['Training_Hours'].fillna(df['Training_Hours'].mean())\n",
    "df['Leave_Days'] = df['Leave_Days'].fillna(df['Leave_Days'].mean())\n",
    "df['Bonus'] = df['Bonus'].fillna(df['Bonus'].mean())\n",
    "\n",
    "df = df[['Salary', 'Experience', 'Performance_Score', 'Projects_Completed', 'Training_Hours', 'Leave_Days', 'Bonus']]\n",
    "df.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Concatenate DataFrames\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "data_1 = {\n",
    "    'Name': ['John', 'Sarah', 'Mike', 'Lisa', 'David'],\n",
    "    'Age': [28, 34, 22, 31, 45],\n",
    "    'City': ['New York', 'Boston', 'Chicago', 'Miami', 'Seattle'],\n",
    "    'Salary': [65000, 72000, 48000, 59000, 85000],\n",
    "    'Department': ['Sales', 'Marketing', 'IT', 'HR', 'Finance']\n",
    "}\n",
    "\n",
    "\n",
    "data_2 = {\n",
    "    'Name': ['Emma', 'Alex', 'Olivia', 'Daniel', 'Sophia'],\n",
    "    'Age': [29, 36, 25, 42, 33],\n",
    "    'City': ['Los Angeles', 'San Francisco', 'Denver', 'Austin', 'Portland'],\n",
    "    'Salary': [68000, 75000, 52000, 88000, 63000],\n",
    "    'Department': ['Marketing', 'Finance', 'IT', 'Sales', 'HR']\n",
    "}\n",
    "\n",
    "# Create DataFrames\n",
    "df_1 = pd.DataFrame(data_1)\n",
    "df_2 = pd.DataFrame(data_2)\n",
    "\n",
    "\n",
    "df_concat = pd.concat([df_1, df_2])\n",
    "df_concat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loop in DataFrame\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Ahmad', 'Siti', 'Aniq', 'Sarah', 'Malik', 'John', 'Mary', 'Ali', 'Lisa', 'David', 'Emma', 'Hassan', 'Fatima', 'James', 'Anna', 'Ahmad'],\n",
    "    'Register_Date': ['15/01/2023', '01/02/2023', '20/01/2023', '10/03/2023', '15/02/2023', '05/01/2023', '28/02/2023', '15/03/2023', '30/01/2023', '10/02/2023', '01/03/2023', '25/01/2023', '20/02/2023', '05/03/2023', '10/01/2023', '15/01/2023'],\n",
    "    'Quitting_Date': ['15-12-2023', '20-11-2023', '05-10-2023', '30-09-2023', '15-08-2023', '01-07-2023', '10-06-2023', '25-05-2023', '12-04-2023', '28-03-2023', '17-04-2023', '22-01-2024', '08-03-2024', '19-04-2024', '30-05-2024', '14-06-2024'],\n",
    "    'ID': [1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1001],\n",
    "    'Age': ['28', None, '32', '27', '30', '35', '29', None, '31', '33', '26', None, '34', '28', '32', '28'],\n",
    "    'Salary': [50000, 45000, None, 55000, 60000, 65000, 48000, 52000, None, 70000, 51000, 53000, None, 57000, 62000, 50000],\n",
    "    'Experience': [3, 2, 6, None, 5, 8, 4, 3, 5, None, 2, 7, 6, None, 4, 3],\n",
    "    'Performance_Score': [8.5, 7.9, 9.2, 8.7, None, 8.9, None, 8.2, 9.0, 8.8, 7.8, 9.1, 8.4, 8.6, None, 8.5],\n",
    "    'Department': ['Sales', 'IT', None, 'HR', 'Marketing', 'Sales', 'IT', 'Marketing', None, 'HR', 'Sales', None, 'IT', 'Marketing', 'HR', 'Sales'],\n",
    "    'Projects_Completed': [12, 8, 15, None, 10, 14, 9, None, 11, 13, None, 16, 7, 12, 9, 12],\n",
    "    'Training_Hours': [40, None, 60, 35, 45, None, 50, 40, 55, 30, 45, None, 50, 35, 40, 40],\n",
    "    'Leave_Days': [10, 12, None, 8, 15, 7, None, 11, 9, 14, 8, 13, None, 10, 12, 10],\n",
    "    'Bonus': [2000, None, 3500, 2500, 4000, 3000, 2200, None, 2800, 4500, 2100, 3200, None, 2700, 3800, 2000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(row)\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Resample Data\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/BTC_1h.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "df.set_index('timestamp', inplace=True)\n",
    "df\n",
    "\n",
    "df.resample('1d').agg({'open': 'first', 'high': 'max', 'low': 'min', 'close': 'last', 'volume': 'sum'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/BTC_1h.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "filtered_date_df = df[(df['timestamp'] > '2023-08-24') & (df['timestamp'] < '2023-08-25')]\n",
    "\n",
    "filtered_date_df.get(['timestamp', 'open', 'high', 'low', 'close', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Rolling Data\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/BTC_1h.csv')\n",
    "\n",
    "df['SMA_10'] = df['close'].rolling(window=10).mean()\n",
    "df['SMA_20'] = df['close'].rolling(window=20).mean()\n",
    "\n",
    "df.get(['timestamp', 'close', 'SMA_10', 'SMA_20']).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Rolling Data Part 2\n",
    "\"\"\"\n",
    "\n",
    "data ={\n",
    "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04', '2023-01-05'],\n",
    "    'Price': [100, 102, 101, 103, 104],\n",
    "    'Volume': [1000, 1000, 1000, 1000, 1000]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df['average_2_days'] = df['Price'].rolling(window=2).mean()\n",
    "df['sum_2_days'] = df['Price'].rolling(window=2).sum()\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/BTC_1h.csv')\n",
    "df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "\n",
    "df['EMA_26'] = ta.ema(df['close'], length=26)\n",
    "df['EMA_50'] = ta.ema(df['close'], length=50)\n",
    "\n",
    "balance = 10000\n",
    "btc_holdings = 0\n",
    "trades = []\n",
    "position = 'CASH'\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx < 26:\n",
    "        continue\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/BTC_1h.csv')\n",
    "df = df[['timestamp', 'open', 'high', 'low', 'close', 'volume']]\n",
    "\n",
    "\n",
    "df['EMA_26'] = ta.ema(df['close'], length=26)\n",
    "df['EMA_50'] = ta.ema(df['close'], length=50)\n",
    "\n",
    "balance = 10000\n",
    "btc_holdings = 0\n",
    "trades = []\n",
    "position = 'CASH'\n",
    "\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx < 26:\n",
    "        continue\n",
    "\n",
    "    prev_data = df.loc[idx-1]\n",
    "    current_data = df.loc[idx]\n",
    "\n",
    "    if current_data['EMA_26'] > current_data['EMA_50'] and prev_data['EMA_26'] <= prev_data['EMA_50'] and position == 'CASH':\n",
    "        btc_holdings = balance / current_data['close']\n",
    "        balance = 0\n",
    "        position = 'IN_POSITION'\n",
    "        trades.append({'timestamp': current_data['timestamp'], 'action': 'buy', 'price': current_data['close'], 'btc_holdings': btc_holdings})\n",
    "    elif current_data['EMA_26'] < current_data['EMA_50'] and prev_data['EMA_26'] >= prev_data['EMA_50'] and position == 'IN_POSITION':\n",
    "        balance = btc_holdings * current_data['close']\n",
    "        btc_holdings = 0\n",
    "        position = 'CASH'\n",
    "        trades.append({'timestamp': current_data['timestamp'], 'action': 'sell', 'price': current_data['close'], 'balance': balance})\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Final balance: {balance +btc_holdings * current_data['close']}\")\n",
    "print(f\"Total trades: {len(trades)}\")\n",
    "print(f\"Trades:\")\n",
    "\n",
    "for trade in trades:\n",
    "    print(trade)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/nextynewb/um-python-bootcamp/main/dataset/BTC_1h.csv')\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "df['EMA_26'] = ta.ema(df['close'], length=26)\n",
    "df['EMA_50'] = ta.ema(df['close'], length=50)\n",
    "\n",
    "df['SMA_26'] = ta.sma(df['close'], length=26)\n",
    "df['SMA_50'] = ta.sma(df['close'], length=50)\n",
    "\n",
    "\n",
    "df['RSI_14'] = ta.rsi(df['close'], length=14)\n",
    "df[['MACD_12_26_9_MACD', 'MACD_12_26_9_MACD_signal', 'MACD_12_26_9_MACD_hist']] = ta.macd(df['close'], length=12, fast=26, slow=9)\n",
    "df[['ADX_14_ADX', 'ADX_14_DIP', 'ADX_14_DIM']] = ta.adx(df['high'], df['low'], df['close'], length=14)\n",
    "df[['BBANDS_20_2_2_upper', 'BBANDS_20_2_2_middle', 'BBANDS_20_2_2_lower', 'BBANDS_20_2_2_width', 'BBANDS_20_2_2_bandwidth']] = ta.bbands(df['close'], length=20, std=2)\n",
    "\n",
    "# Stochastic Oscillator\n",
    "df[['STOCH_14_3_3_k', 'STOCH_14_3_3_d']] = ta.stoch(df['high'], df['low'], df['close'], k=14, d=3, smooth_k=3)\n",
    "\n",
    "# Average True Range (ATR)\n",
    "df['ATR_14'] = ta.atr(df['high'], df['low'], df['close'], length=14)\n",
    "\n",
    "# On-Balance Volume (OBV)\n",
    "df['OBV'] = ta.obv(df['close'], df['volume'])\n",
    "\n",
    "# Commodity Channel Index (CCI)\n",
    "df['CCI_20'] = ta.cci(df['high'], df['low'], df['close'], length=20)\n",
    "\n",
    "# Williams %R\n",
    "df['WILLR_14'] = ta.willr(df['high'], df['low'], df['close'], length=14)\n",
    "\n",
    "# Parabolic SAR\n",
    "df['PSAR'] = ta.psar(df['high'], df['low'])['PSARl_0.02_0.2']\n",
    "# Ichimoku Cloud\n",
    "\n",
    "# Keltner Channel\n",
    "keltner = ta.kc(df['high'], df['low'], df['close'], length=20)\n",
    "df = pd.concat([df, keltner], axis=1)\n",
    "\n",
    "# Chande Momentum Oscillator\n",
    "df['CMO_14'] = ta.cmo(df['close'], length=14)\n",
    "\n",
    "# Money Flow Index\n",
    "df['MFI_14'] = ta.mfi(df['high'], df['low'], df['close'], df['volume'], length=14)\n",
    "\n",
    "\n",
    "# Awesome Oscillator\n",
    "df['AO'] = ta.ao(df['high'], df['low'])\n",
    "\n",
    "\n",
    "# Check Doji\n",
    "df['DOJI'] = ta.cdl_doji(df['open'], df['high'], df['low'], df['close'])\n",
    "\n",
    "\n",
    "# More can be check at https://github.com/Data-Analisis/Technical-Analysis-Indicators---Pandas?tab=readme-ov-file#candles-3\n",
    "\n",
    "df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ta.bbands(df['close'], length=20, std=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
